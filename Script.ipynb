{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1056cd91",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f521df1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T21:37:11.439860Z",
     "start_time": "2022-01-31T21:37:10.245684Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3b070c",
   "metadata": {},
   "source": [
    "## Collect Product_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfed8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conseguindo o HTML\n",
    "html = requests.get('https://www2.hm.com/en_us/men/products/jeans.html', headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "soup = BeautifulSoup(html.text,'html.parser')\n",
    "\n",
    "# Conseguindo todas as vitrines (Paginação)\n",
    "qtd_produtos = int(soup.find('h2',class_='load-more-heading')['data-total'])\n",
    "html = requests.get('https://www2.hm.com/en_us/men/products/jeans.html?sort=stock&image-size=small&image=model&offset=0&page-size='+str(qtd_produtos), headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "soup = BeautifulSoup(html.text,'html.parser')\n",
    "\n",
    "# Achar cada vitrine\n",
    "produtos = soup.findAll('article',class_='hm-product-item')\n",
    "\n",
    "# Conseguindo o link de cada vitrine\n",
    "links = []\n",
    "for produto in produtos:\n",
    "    links.append('https://www2.hm.com/'+produto.find('a')['href'])\n",
    "    \n",
    "# Achar o código do produto\n",
    "lst_codigo = []\n",
    "for link in links:\n",
    "    html = requests.get(link, headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    for c in range(len(soup.findAll('a',class_='filter-option miniature'))):\n",
    "        lst_codigo.append(soup.findAll('a',class_='filter-option miniature')[c]['data-articlecode'])\n",
    "    for c in range(len(soup.findAll('a',class_='filter-option miniature active'))):\n",
    "        lst_codigo.append(soup.findAll('a',class_='filter-option miniature active')[c]['data-articlecode'])\n",
    "\n",
    "# Removendo os códigos duplicates (Granularidade)\n",
    "dados = pd.DataFrame(lst_codigo,columns=['id'])\n",
    "dados.drop_duplicates(subset=['id'],inplace=True)\n",
    "dados.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1702a47f",
   "metadata": {},
   "source": [
    "## Collect Product Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc640273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo os Links\n",
    "links = []\n",
    "for cod in dados['id']:\n",
    "    links.append('https://www2.hm.com/en_us/productpage.'+ cod +'.html')\n",
    "dados['link'] = links\n",
    "\n",
    "# Nome\n",
    "lst_name = []\n",
    "for link in dados['link']:\n",
    "    html = requests.get(link, headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    lst_name.append(' '.join(soup.find('h1',class_='primary product-item-headline').string.split()))\n",
    "dados['name'] = lst_name\n",
    "\n",
    "# Cores\n",
    "cores = []\n",
    "for link in dados['link']:\n",
    "    html = requests.get(link, headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    cor = soup.find('a',class_='filter-option miniature active')['data-color']\n",
    "    cores.append(cor)\n",
    "dados['color'] = cores\n",
    "\n",
    "# Características\n",
    "descricao = {}\n",
    "lst = []\n",
    "for link in dados['link']:\n",
    "    html = requests.get(link, headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    for x in soup.findAll('div',class_='pdp-description-list-item'):\n",
    "        if x.select('li') == []:\n",
    "            keys = str(x.select('dt'))\n",
    "            values = str(x.select('dd'))\n",
    "            descricao[keys] = values\n",
    "        else:\n",
    "            keys = str(x.select('dt'))\n",
    "            values = str(x.select('li'))\n",
    "            descricao[keys] = values\n",
    "    lst.append(descricao.copy())\n",
    "    descricao.clear()\n",
    "descricao = pd.DataFrame(lst)\n",
    "descricao.drop('[<dt>Art. No.</dt>]',1,inplace=True)\n",
    "dados = pd.concat([dados,descricao],axis=1)\n",
    "\n",
    "# Descrição\n",
    "descs = []\n",
    "for link in dados['link']:\n",
    "    html = requests.get(link, headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    desc = soup.find('p',class_='pdp-description-text').get_text()\n",
    "    descs.append(desc)\n",
    "dados['description'] = descs\n",
    "\n",
    "lst_price = []\n",
    "for link in dados['link']:\n",
    "    html = requests.get(link, headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    soup = soup.find('section',class_='name-price')\n",
    "    lst_price.append(soup.find('span').get_text().split()[0])\n",
    "dados['price'] = lst_price\n",
    "\n",
    "\n",
    "# Add timestamp\n",
    "dados['timestamp'] = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d8fd41",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "columns_name_list = []\n",
    "for coluna in dados.columns.values:\n",
    "    try:\n",
    "        columns_name_list.append((re.search('>(.+)<',coluna).group(1)).lower())\n",
    "    except:\n",
    "        columns_name_list.append(coluna.lower())\n",
    "dados.columns = columns_name_list\n",
    "\n",
    "# Name - pattern\n",
    "dados['name'] = dados['name'].apply(lambda x: x.replace(' ','_').lower())\n",
    "\n",
    "# Color - Pattern\n",
    "dados['color'] = dados['color'].apply(lambda x: x.replace(' ','_').lower())\n",
    "dados['color'] = dados['color'].apply(lambda x: x.replace('-','_').lower())\n",
    "\n",
    "# Fit - Pattern\n",
    "dados['fit'] = dados['fit'].apply(lambda x: (re.search('>(.+)<',x).group(1)))\n",
    "dados['fit'] = dados['fit'].apply(lambda x: x.replace(' ','_').lower())\n",
    "\n",
    "# Size - Drop\n",
    "dados.drop('size',1,inplace=True)\n",
    "\n",
    "# Product Safety - Drop\n",
    "dados.drop('product safety',1,inplace=True)\n",
    "\n",
    "# Price - Pattern\n",
    "dados['price'] = dados['price'].apply(lambda x: float(x.split('$')[-1]))\n",
    "\n",
    "# Id Group - Create\n",
    "dados['id_group'] = dados['id'].apply(lambda x: int(str(x)[:7]))\n",
    "dados['id_group'].apply(lambda x: '0'+str(x)) # add 0 no início, como no product id e transformar em str\n",
    "\n",
    "# More Sustainable Materials - Drop\n",
    "dados.drop('more sustainable materials',axis=1,inplace=True)\n",
    "\n",
    "#######################################################################################################################################################################################################\n",
    "\n",
    "# Composition - Pattern \n",
    "dados['composition'] = dados['composition'].apply(lambda x: x.lower())\n",
    "\n",
    "# Composition - Separate into several columns\n",
    "dados['composition'] = dados['composition'].apply(lambda x: (re.search('>(.+)<',x).group(1)))\n",
    "dados['composition'] = dados['composition'].apply(lambda x: x.replace('</li>',''))\n",
    "dados['composition'] = dados['composition'].apply(lambda x: x.replace('<li>',''))\n",
    "df_aux = dados.copy()\n",
    "df_aux['composition_list'] = np.nan\n",
    "\n",
    "# O que fazer com compositions nulas\n",
    "index_comp_nan = df_aux[df_aux.isna()['composition']].index.values\n",
    "for index in index_comp_nan:\n",
    "    df_aux.loc[index_comp_nan,'composition_list'] = 'Não Fornecido'\n",
    "\n",
    "# o que fazer com Clean Compositions\n",
    "for c in range(dados.shape[0]):\n",
    "    lista_comp = re.findall('(\\d{1,3})%',dados.loc[c,'composition'])\n",
    "    for i in range(len(lista_comp)):\n",
    "        lista_comp[i] = float(lista_comp[i])\n",
    "    soma = sum(lista_comp)\n",
    "    if soma == 100 and ':' not in dados.loc[c,'composition']:\n",
    "        df_aux['composition_list'][c] = list(filter(None,re.split('%|, | ',dados.loc[c,'composition'].replace(', ',''))))\n",
    "        \n",
    "        \n",
    "# retirando o pocket do composition\n",
    "# quem só tiver pocket é dado como não fornecido\n",
    "\n",
    "###############################################################################################################\n",
    "\n",
    "# Ver os que restam sem composition no comp_list\n",
    "index_comp_nao_resolvida = df_aux[df_aux.isna()['composition_list']].index.values\n",
    "\n",
    "# Ver, desses sem comp, quais possuem a palavra pocket nele\n",
    "l = []\n",
    "ind = []\n",
    "for index in index_comp_nao_resolvida:\n",
    "    try:\n",
    "        l.append(str(re.search('(pocket.+)',df_aux.loc[index,'composition']).group(1)))\n",
    "        ind.append(index)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# criar um df dos que tem pocket na comp\n",
    "df_pocket = pd.DataFrame(l,ind)\n",
    "df_pocket.reset_index(inplace=True)\n",
    "df_pocket.rename(columns={0:'comp'},inplace=True)\n",
    "df_pocket = df_pocket.join(df_aux.loc[index_comp_nao_resolvida,'composition'],on='index')\n",
    "\n",
    "# Extraindo as porcentagens\n",
    "df_pocket['pct'] = np.nan\n",
    "for c in range(df_pocket.shape[0]):\n",
    "    df_pocket['pct'][c] = re.findall('(\\d{1,3})%',df_pocket.loc[c,'comp'])\n",
    "\n",
    "# Separar as porcentagens de 100 em 100, a primeira é a do pocket (pct_pocket), as demais não (pct_clothes)\n",
    "pct_pocket = []\n",
    "pct_clothes = []\n",
    "for numeros in df_pocket['pct']:\n",
    "    soma_anterior = 0\n",
    "    soma_final = 0\n",
    "    count = 0\n",
    "    for num in numeros:\n",
    "            num = int(num)\n",
    "            soma_final = soma_anterior + num\n",
    "            count = count + 1\n",
    "            soma_anterior = soma_final\n",
    "            if soma_final == 100:\n",
    "                pct_clothes.append(numeros[count:].copy())\n",
    "                pct_pocket.append(numeros[:count].copy())\n",
    "df_pocket['pct_clothes'] = pct_clothes\n",
    "df_pocket['pct_pocket'] = pct_pocket\n",
    "\n",
    "# Tirando só a parte do pocket das compositions\n",
    "lst_sem_pocket = []\n",
    "for index in range(df_pocket.shape[0]):\n",
    "    frase = df_pocket.loc[index,'composition']\n",
    "    pattern = '(pocket.+{}%)'.format(df_pocket.loc[index,'pct_pocket'][-1])\n",
    "    lst_sem_pocket.append(frase.replace(re.search(pattern,frase).group(1),''))\n",
    "df_pocket = pd.concat([df_pocket,pd.Series(lst_sem_pocket)],axis=1)\n",
    "df_pocket.rename(columns={0:'composition_sem_pocket'},inplace=True)\n",
    "\n",
    "# se sobrar nada? os vazios n tem composition (pq eles só tinham pocket)\n",
    "for index in range(df_pocket.shape[0]):\n",
    "    if df_pocket.loc[index,'composition_sem_pocket'] == ' ':\n",
    "        df_aux.loc[df_pocket.loc[index,'index'],'composition_list'] = 'Não Fornecido'\n",
    "        \n",
    "# se sobrar só as composições, quero colocá-las no meu composition list\n",
    "for c in range(df_pocket.shape[0]):\n",
    "    lista_comp = re.findall('(\\d{1,3})%',df_pocket.loc[c,'composition_sem_pocket'])\n",
    "    for i in range(len(lista_comp)):\n",
    "        lista_comp[i] = float(lista_comp[i])\n",
    "    soma = sum(lista_comp)\n",
    "    if soma == 100 and ':' not in df_pocket.loc[c,'composition_sem_pocket']:\n",
    "        df_aux['composition_list'][df_pocket.loc[c,'index']] = list(filter(None,re.split('%|, | ',df_pocket.loc[c,'composition_sem_pocket'].replace(', ',''))))\n",
    "\n",
    "# criar nova coluna com os compositions, só que sem o pocket\n",
    "df_pocket.set_index('index',inplace=True)\n",
    "df_aux['composition_sem_pocket'] = np.nan\n",
    "for c in range(df_aux.shape[0]):\n",
    "    try:\n",
    "        df_aux['composition_sem_pocket'][c] = df_pocket['composition_sem_pocket'][c]\n",
    "    except:\n",
    "        df_aux['composition_sem_pocket'][c] = df_aux['composition'][c]\n",
    "        \n",
    "        \n",
    "# retirando o lining do composition\n",
    "# quem só tiver lining é dado como não fornecido\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "# Ver os que restam sem composition no comp_list\n",
    "index_comp_nao_resolvida = df_aux[df_aux.isna()['composition_list']].index.values\n",
    "\n",
    "# Ver, desses sem comp e sem pocket, quais possuem a palavra lining nele\n",
    "l = []\n",
    "ind = []\n",
    "for index in index_comp_nao_resolvida:\n",
    "    try:\n",
    "        l.append(str(re.search('(lining.+)',df_aux.loc[index,'composition_sem_pocket']).group(1)))\n",
    "        ind.append(index)\n",
    "    except:\n",
    "        pass\n",
    "# criar um df dos que tem lining e não tem pocket\n",
    "df_lining = pd.DataFrame(l,ind)\n",
    "df_lining.reset_index(inplace=True)\n",
    "df_lining.rename(columns={0:'comp'},inplace=True)\n",
    "df_lining = df_lining.join(df_aux.loc[index_comp_nao_resolvida,'composition_sem_pocket'],on='index')\n",
    "\n",
    "# Extraindo as porcentagens\n",
    "df_lining['pct'] = np.nan\n",
    "for c in range(df_lining.shape[0]):\n",
    "    df_lining['pct'][c] = re.findall('(\\d{1,3})%',df_lining.loc[c,'comp'])\n",
    "\n",
    "# Separar as porcentagens de 100 em 100, a primeira é a do lining (pct_lining), as demais não (pct_clothes)\n",
    "pct_lining = []\n",
    "pct_clothes = []\n",
    "for numeros in df_lining['pct']:\n",
    "    soma_anterior = 0\n",
    "    soma_final = 0\n",
    "    count = 0\n",
    "    for num in numeros:\n",
    "            num = int(num)\n",
    "            soma_final = soma_anterior + num\n",
    "            count = count + 1\n",
    "            soma_anterior = soma_final\n",
    "            if soma_final == 100:\n",
    "                pct_clothes.append(numeros[count:].copy())\n",
    "                pct_lining.append(numeros[:count].copy())\n",
    "df_lining['pct_clothes'] = pct_clothes\n",
    "df_lining['pct_lining'] = pct_lining\n",
    "\n",
    "# Tirando só a parte do lining das comp\n",
    "lst_sem_lining = []\n",
    "for index in range(df_lining.shape[0]):\n",
    "        frase = df_lining.loc[index,'composition_sem_pocket']\n",
    "        pattern = '(lining.+{}%)'.format(df_lining.loc[index,'pct_lining'][-1])\n",
    "        lst_sem_lining.append(frase.replace(re.search(pattern,frase).group(1),''))\n",
    "df_lining = pd.concat([df_lining,pd.Series(lst_sem_lining)],axis=1)\n",
    "df_lining.rename(columns={0:'comp_sem_lining'},inplace=True)\n",
    "\n",
    "# se sobrar nada? os vazios n tem composition (pq eles só tinham lining ou só lining e pocket)\n",
    "for index in range(df_lining.shape[0]):\n",
    "    if df_lining.loc[index,'comp_sem_lining'] == ' ':\n",
    "        df_aux.loc[df_lining.loc[index,'index'],'composition_list'] = 'Não fornecido'\n",
    "\n",
    "# se sobrar só as composições, quero colocá-las no meu composition list\n",
    "for c in range(df_lining.shape[0]):\n",
    "    lista_comp = re.findall('(\\d{1,3})%',df_lining.loc[c,'comp_sem_lining'])\n",
    "    for i in range(len(lista_comp)):\n",
    "        lista_comp[i] = float(lista_comp[i])\n",
    "    soma = sum(lista_comp)\n",
    "    if soma == 100 and ':' not in df_lining.loc[c,'comp_sem_lining']:\n",
    "        df_aux['composition_list'][df_lining.loc[c,'index']] = list(filter(None,re.split('%|, | ',df_lining.loc[c,'comp_sem_lining'].replace(', ',''))))\n",
    "\n",
    "# criar nova coluna com os compositions, só que sem o pocket e sem o lining\n",
    "df_lining.set_index('index',inplace=True)\n",
    "df_aux['composition_sem_pocket_e_sem_lining'] = np.nan\n",
    "for c in range(df_aux.shape[0]):\n",
    "    try:\n",
    "        df_aux['composition_sem_pocket_e_sem_lining'][c] = df_lining['comp_sem_lining'][c]\n",
    "    except:\n",
    "        df_aux['composition_sem_pocket_e_sem_lining'][c] = df_aux['composition_sem_pocket'][c] # mantenho o sem pocket, se já n tiver lining\n",
    "        \n",
    "        \n",
    "# retirando o shell do composition\n",
    "\n",
    "# quem só tiver shell a gente bota shell\n",
    "# quem tiver shell + comp a gente bota comp\n",
    "# quem tiver outra categoria a gente bota \"inconclusivo\"\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "# Ver os que restam sem composition no comp_list\n",
    "index_comp_nao_resolvida = df_aux[df_aux.isna()['composition_list']].index.values\n",
    "\n",
    "# Ver, desses sem comp e sem pocket, quais possuem a palavra lining nele\n",
    "l = []\n",
    "ind = []\n",
    "for index in index_comp_nao_resolvida:\n",
    "    try:\n",
    "        l.append(str(re.search('(shell.+)',df_aux.loc[index,'composition_sem_pocket_e_sem_lining']).group(1)))\n",
    "        ind.append(index)\n",
    "    except:\n",
    "        pass\n",
    "# criar um df dos que tem shell e não tem pocket nem lining\n",
    "df_shell = pd.DataFrame(l,ind)\n",
    "df_shell.reset_index(inplace=True)\n",
    "df_shell.rename(columns={0:'comp'},inplace=True)\n",
    "df_shell = df_shell.join(df_aux.loc[index_comp_nao_resolvida,'composition_sem_pocket_e_sem_lining'],on='index')\n",
    "\n",
    "# Extraindo as porcentagens\n",
    "df_shell['pct'] = np.nan\n",
    "for c in range(df_shell.shape[0]):\n",
    "    df_shell['pct'][c] = re.findall('(\\d{1,3})%',df_shell.loc[c,'comp'])\n",
    "\n",
    "# Separar as porcentagens de 100 em 100, a primeira é a do shell (pct_shell), as demais não (pct_clothes)\n",
    "pct_shell = []\n",
    "pct_clothes = []\n",
    "for numeros in df_shell['pct']:\n",
    "    soma_anterior = 0\n",
    "    soma_final = 0\n",
    "    count = 0\n",
    "    for num in numeros:\n",
    "            num = int(num)\n",
    "            soma_final = soma_anterior + num\n",
    "            count = count + 1\n",
    "            soma_anterior = soma_final\n",
    "            if soma_final == 100:\n",
    "                pct_clothes.append(numeros[count:].copy())\n",
    "                pct_shell.append(numeros[:count].copy())\n",
    "df_shell['pct_clothes'] = pct_clothes\n",
    "df_shell['pct_shell'] = pct_shell\n",
    "\n",
    "# Tirando só a parte do shell das comp\n",
    "lst_sem_shell = []\n",
    "for index in range(df_shell.shape[0]):\n",
    "        frase = df_shell.loc[index,'composition_sem_pocket_e_sem_lining']\n",
    "        pattern = '(shell.+{}%)'.format(df_shell.loc[index,'pct_shell'][-1])\n",
    "        lst_sem_shell.append(frase.replace(re.search(pattern,frase).group(1),''))\n",
    "df_shell = pd.concat([df_shell,pd.Series(lst_sem_shell)],axis=1)\n",
    "df_shell.rename(columns={0:'comp_sem_shell'},inplace=True)\n",
    "\n",
    "# se sobrar nada? os vazios so tinham shell, ent vamos usar eles\n",
    "for c in range(df_shell.shape[0]):\n",
    "    if not df_shell.loc[c,'comp_sem_shell'].isalpha():\n",
    "        df_aux['composition_list'][df_shell.loc[c,'index']] = list(filter(None,re.split('%|, | ',df_shell.loc[c,'composition_sem_pocket_e_sem_lining'].replace(', ','').replace('shell: ',''))))\n",
    "    \n",
    "# se sobrar só as composições, quero colocá-las no meu composition list\n",
    "for c in range(df_shell.shape[0]):\n",
    "    lista_comp = re.findall('(\\d{1,3})%',df_shell.loc[c,'comp_sem_shell'])\n",
    "    for i in range(len(lista_comp)):\n",
    "        lista_comp[i] = float(lista_comp[i])\n",
    "    soma = sum(lista_comp)\n",
    "    if soma == 100 and ':' not in df_shell.loc[c,'comp_sem_shell']:\n",
    "        df_aux['composition_list'][df_shell.loc[c,'index']] = list(filter(None,re.split('%|, | ',df_shell.loc[c,'comp_sem_shell'].replace(', ',''))))\n",
    "\n",
    "# criar nova coluna com os compositions, só que sem o pocket sem o lining e sem o shell\n",
    "df_shell.set_index('index',inplace=True)\n",
    "df_aux['composition_sem_pocket_e_sem_lining_e_sem_shell'] = np.nan\n",
    "for c in range(df_aux.shape[0]):\n",
    "    try:\n",
    "        df_aux['composition_sem_pocket_e_sem_lining_e_sem_shell'][c] = df_lining['comp_sem_shell'][c]\n",
    "    except:\n",
    "        df_aux['composition_sem_pocket_e_sem_lining_e_sem_shell'][c] = df_aux['composition_sem_pocket_e_sem_lining'][c] # mantenho o sem pocket e sem lining, se já n tiver shell\n",
    "        \n",
    "        \n",
    "# Ver os que restam sem composition no comp_list\n",
    "index_comp_nao_resolvida = df_aux[df_aux.isna()['composition_list']].index.values\n",
    "for index in index_comp_nao_resolvida:\n",
    "    df_aux.loc[index_comp_nao_resolvida,'composition_list'] = 'Inconclusivo'\n",
    "    \n",
    "dados = pd.concat([dados,df_aux['composition_list']],axis=1)\n",
    "\n",
    "# Transformando as composições em colunas\n",
    "comp_dict = {}\n",
    "comp_list = []\n",
    "\n",
    "for comp in dados['composition_list']:\n",
    "    for c in range(0,len(comp),2):\n",
    "        comp_dict[comp[c]] = comp[c+1]\n",
    "    comp_list.append(comp_dict.copy())\n",
    "\n",
    "df_compositions = pd.DataFrame(comp_list).fillna(0)\n",
    "\n",
    "for columns in df_compositions: # convert to float\n",
    "    df_compositions[columns] = df_compositions[columns].astype('float')\n",
    "\n",
    "dados = pd.concat([dados,df_compositions],axis=1)\n",
    "\n",
    "dados.drop(['composition','composition_list'],axis=1,inplace=True) # Drop other composition columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################################################################################################################################3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a1e0a",
   "metadata": {},
   "source": [
    "## Database Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a24939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and Connecting with a SQLite3 Database\n",
    "db = sq.create_engine('sqlite:///hm_db.sqlite',echo=False)\n",
    "conn = db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df58232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a tabela\n",
    "query = \"\"\"CREATE TABLE men_jeans (\n",
    "id               TEXT,\n",
    "link             TEXT,\n",
    "name             TEXT,\n",
    "color            TEXT,\n",
    "fit              TEXT,\n",
    "description      TEXT,\n",
    "price            REAL,\n",
    "timestamp        TEXT,\n",
    "id_group         TEXT,\n",
    "cotton           REAL,\n",
    "spandex          REAL,\n",
    "polyester        REAL,\n",
    "elasterell-p     REAL,\n",
    "modal            REAL)\n",
    "\"\"\"\n",
    "\n",
    "conn.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando o dataframe\n",
    "dados.to_sql('men_jeans',conn,if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8047e",
   "metadata": {},
   "source": [
    "# Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "630f23d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T20:50:32.267405Z",
     "start_time": "2022-01-31T20:50:32.263435Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# Checking if the log folder exists, if not, it creates\n",
    "if not os.path.exists('/Users/nando/Comunidade DS/ds_ao_dev/logs'):\n",
    "    os.makedirs('/Users/nando/Comunidade DS/ds_ao_dev/logs')\n",
    "\n",
    "# Log Configuration\n",
    "logging.basicConfig(filename='/Users/nando/Comunidade DS/ds_ao_dev/logs/webscraping.txt',level=logging.DEBUG,format='%(asctime)s - %(levelname)s - %(name)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a349f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f356a37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T20:17:11.528526Z",
     "start_time": "2022-01-31T20:12:20.413989Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ======================================== COLETA DE DADOS ===============================================================\n",
    "\n",
    "# PASSOS INICIAIS ------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Conseguindo o HTML\n",
    "html = requests.get('https://www2.hm.com/en_us/men/products/jeans.html', headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "soup = BeautifulSoup(html.text,'html.parser')\n",
    "\n",
    "# Conseguindo todas as vitrines (Paginação)\n",
    "qtd_produtos = int(soup.find('h2',class_='load-more-heading')['data-total'])\n",
    "html = requests.get('https://www2.hm.com/en_us/men/products/jeans.html?sort=stock&image-size=small&image=model&offset=0&page-size='+str(qtd_produtos), headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "soup = BeautifulSoup(html.text,'html.parser')\n",
    "\n",
    "# Achar cada vitrine\n",
    "produtos = soup.findAll('article',class_='hm-product-item')\n",
    "\n",
    "# Conseguindo o link de cada vitrine\n",
    "links = []\n",
    "for produto in produtos:\n",
    "    links.append('https://www2.hm.com/'+produto.find('a')['href'])\n",
    "    \n",
    "# Achar o código do produto\n",
    "lst_codigo = []\n",
    "for link in links:\n",
    "    html = requests.get(link, headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    for c in range(len(soup.findAll('a',class_='filter-option miniature'))):\n",
    "        lst_codigo.append(soup.findAll('a',class_='filter-option miniature')[c]['data-articlecode'])\n",
    "    for c in range(len(soup.findAll('a',class_='filter-option miniature active'))):\n",
    "        lst_codigo.append(soup.findAll('a',class_='filter-option miniature active')[c]['data-articlecode'])\n",
    "\n",
    "# Removendo os códigos duplicates (Granularidade)\n",
    "dados = pd.DataFrame(lst_codigo,columns=['id'])\n",
    "dados.drop_duplicates(subset=['id'],inplace=True)\n",
    "dados.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "# FEATURES DO PRODUTO ------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Obtendo os Links\n",
    "links = []\n",
    "for cod in dados['id']:\n",
    "    links.append('https://www2.hm.com/en_us/productpage.'+ cod +'.html')\n",
    "dados['link'] = links\n",
    "\n",
    "# Nome\n",
    "lst_name = []\n",
    "for link in dados['link']:\n",
    "    html = requests.get(link, headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    lst_name.append(' '.join(soup.find('h1',class_='primary product-item-headline').string.split()))\n",
    "dados['name'] = lst_name\n",
    "\n",
    "# Cores\n",
    "cores = []\n",
    "for link in dados['link']:\n",
    "    html = requests.get(link, headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    cor = soup.find('a',class_='filter-option miniature active')['data-color']\n",
    "    cores.append(cor)\n",
    "dados['color'] = cores\n",
    "\n",
    "# Características\n",
    "descricao = {}\n",
    "lst = []\n",
    "for link in dados['link']:\n",
    "    html = requests.get(link, headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    for x in soup.findAll('div',class_='pdp-description-list-item'):\n",
    "        if x.select('li') == []:\n",
    "            keys = str(x.select('dt'))\n",
    "            values = str(x.select('dd'))\n",
    "            descricao[keys] = values\n",
    "        else:\n",
    "            keys = str(x.select('dt'))\n",
    "            values = str(x.select('li'))\n",
    "            descricao[keys] = values\n",
    "    lst.append(descricao.copy())\n",
    "    descricao.clear()\n",
    "descricao = pd.DataFrame(lst)\n",
    "descricao.drop('[<dt>Art. No.</dt>]',1,inplace=True)\n",
    "dados = pd.concat([dados,descricao],axis=1)\n",
    "\n",
    "# Descrição\n",
    "descs = []\n",
    "for link in dados['link']:\n",
    "    html = requests.get(link, headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    desc = soup.find('p',class_='pdp-description-text').get_text()\n",
    "    descs.append(desc)\n",
    "dados['description'] = descs\n",
    "\n",
    "lst_price = []\n",
    "for link in dados['link']:\n",
    "    html = requests.get(link, headers={'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36'})\n",
    "    soup = BeautifulSoup(html.text,'html.parser')\n",
    "    soup = soup.find('section',class_='name-price')\n",
    "    lst_price.append(soup.find('span').get_text().split()[0])\n",
    "dados['price'] = lst_price\n",
    "\n",
    "\n",
    "# Add timestamp\n",
    "dados['timestamp'] = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "# ================================== LIMPEZA DE DADOS ===============================================\n",
    "\n",
    "# Rename columns\n",
    "columns_name_list = []\n",
    "for coluna in dados.columns.values:\n",
    "    try:\n",
    "        columns_name_list.append((re.search('>(.+)<',coluna).group(1)).lower())\n",
    "    except:\n",
    "        columns_name_list.append(coluna.lower())\n",
    "dados.columns = columns_name_list\n",
    "\n",
    "# Name - pattern\n",
    "dados['name'] = dados['name'].apply(lambda x: x.replace(' ','_').lower())\n",
    "\n",
    "# Color - Pattern\n",
    "dados['color'] = dados['color'].apply(lambda x: x.replace(' ','_').lower())\n",
    "dados['color'] = dados['color'].apply(lambda x: x.replace('-','_').lower())\n",
    "\n",
    "# Fit - Pattern\n",
    "dados['fit'] = dados['fit'].apply(lambda x: (re.search('>(.+)<',x).group(1)))\n",
    "dados['fit'] = dados['fit'].apply(lambda x: x.replace(' ','_').lower())\n",
    "\n",
    "# Size - Drop\n",
    "dados.drop('size',1,inplace=True)\n",
    "\n",
    "# Product Safety - Drop\n",
    "dados.drop('product safety',1,inplace=True)\n",
    "\n",
    "# Price - Pattern\n",
    "dados['price'] = dados['price'].apply(lambda x: float(x.split('$')[-1]))\n",
    "\n",
    "# Id Group - Create\n",
    "dados['id_group'] = dados['id'].apply(lambda x: int(str(x)[:7]))\n",
    "\n",
    "# More Sustainable Materials - Drop\n",
    "dados.drop('more sustainable materials',axis=1,inplace=True)\n",
    "\n",
    "#######################################################################################################################################################################################################\n",
    "\n",
    "# Composition - Pattern \n",
    "dados['composition'] = dados['composition'].apply(lambda x: x.lower())\n",
    "\n",
    "# Composition - Separate into several columns\n",
    "dados['composition'] = dados['composition'].apply(lambda x: (re.search('>(.+)<',x).group(1)))\n",
    "dados['composition'] = dados['composition'].apply(lambda x: x.replace('</li>',''))\n",
    "dados['composition'] = dados['composition'].apply(lambda x: x.replace('<li>',''))\n",
    "df_aux = dados.copy()\n",
    "df_aux['composition_list'] = np.nan\n",
    "\n",
    "# O que fazer com compositions nulas\n",
    "index_comp_nan = df_aux[df_aux.isna()['composition']].index.values\n",
    "for index in index_comp_nan:\n",
    "    df_aux.loc[index_comp_nan,'composition_list'] = 'Não Fornecido'\n",
    "\n",
    "# o que fazer com Clean Compositions\n",
    "for c in range(dados.shape[0]):\n",
    "    lista_comp = re.findall('(\\d{1,3})%',dados.loc[c,'composition'])\n",
    "    for i in range(len(lista_comp)):\n",
    "        lista_comp[i] = float(lista_comp[i])\n",
    "    soma = sum(lista_comp)\n",
    "    if soma == 100 and ':' not in dados.loc[c,'composition']:\n",
    "        df_aux['composition_list'][c] = list(filter(None,re.split('%|, | ',dados.loc[c,'composition'].replace(', ',''))))\n",
    "        \n",
    "        \n",
    "# retirando o pocket do composition\n",
    "# quem só tiver pocket é dado como não fornecido\n",
    "\n",
    "###############################################################################################################\n",
    "\n",
    "# Ver os que restam sem composition no comp_list\n",
    "index_comp_nao_resolvida = df_aux[df_aux.isna()['composition_list']].index.values\n",
    "\n",
    "# Ver, desses sem comp, quais possuem a palavra pocket nele\n",
    "l = []\n",
    "ind = []\n",
    "for index in index_comp_nao_resolvida:\n",
    "    try:\n",
    "        l.append(str(re.search('(pocket.+)',df_aux.loc[index,'composition']).group(1)))\n",
    "        ind.append(index)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# criar um df dos que tem pocket na comp\n",
    "df_pocket = pd.DataFrame(l,ind)\n",
    "df_pocket.reset_index(inplace=True)\n",
    "df_pocket.rename(columns={0:'comp'},inplace=True)\n",
    "df_pocket = df_pocket.join(df_aux.loc[index_comp_nao_resolvida,'composition'],on='index')\n",
    "\n",
    "# Extraindo as porcentagens\n",
    "df_pocket['pct'] = np.nan\n",
    "for c in range(df_pocket.shape[0]):\n",
    "    df_pocket['pct'][c] = re.findall('(\\d{1,3})%',df_pocket.loc[c,'comp'])\n",
    "\n",
    "# Separar as porcentagens de 100 em 100, a primeira é a do pocket (pct_pocket), as demais não (pct_clothes)\n",
    "pct_pocket = []\n",
    "pct_clothes = []\n",
    "for numeros in df_pocket['pct']:\n",
    "    soma_anterior = 0\n",
    "    soma_final = 0\n",
    "    count = 0\n",
    "    for num in numeros:\n",
    "            num = int(num)\n",
    "            soma_final = soma_anterior + num\n",
    "            count = count + 1\n",
    "            soma_anterior = soma_final\n",
    "            if soma_final == 100:\n",
    "                pct_clothes.append(numeros[count:].copy())\n",
    "                pct_pocket.append(numeros[:count].copy())\n",
    "df_pocket['pct_clothes'] = pct_clothes\n",
    "df_pocket['pct_pocket'] = pct_pocket\n",
    "\n",
    "# Tirando só a parte do pocket das compositions\n",
    "lst_sem_pocket = []\n",
    "for index in range(df_pocket.shape[0]):\n",
    "    frase = df_pocket.loc[index,'composition']\n",
    "    pattern = '(pocket.+{}%)'.format(df_pocket.loc[index,'pct_pocket'][-1])\n",
    "    lst_sem_pocket.append(frase.replace(re.search(pattern,frase).group(1),''))\n",
    "df_pocket = pd.concat([df_pocket,pd.Series(lst_sem_pocket)],axis=1)\n",
    "df_pocket.rename(columns={0:'composition_sem_pocket'},inplace=True)\n",
    "\n",
    "# se sobrar nada? os vazios n tem composition (pq eles só tinham pocket)\n",
    "for index in range(df_pocket.shape[0]):\n",
    "    if df_pocket.loc[index,'composition_sem_pocket'] == ' ':\n",
    "        df_aux.loc[df_pocket.loc[index,'index'],'composition_list'] = 'Não Fornecido'\n",
    "        \n",
    "# se sobrar só as composições, quero colocá-las no meu composition list\n",
    "for c in range(df_pocket.shape[0]):\n",
    "    lista_comp = re.findall('(\\d{1,3})%',df_pocket.loc[c,'composition_sem_pocket'])\n",
    "    for i in range(len(lista_comp)):\n",
    "        lista_comp[i] = float(lista_comp[i])\n",
    "    soma = sum(lista_comp)\n",
    "    if soma == 100 and ':' not in df_pocket.loc[c,'composition_sem_pocket']:\n",
    "        df_aux['composition_list'][df_pocket.loc[c,'index']] = list(filter(None,re.split('%|, | ',df_pocket.loc[c,'composition_sem_pocket'].replace(', ',''))))\n",
    "\n",
    "# criar nova coluna com os compositions, só que sem o pocket\n",
    "df_pocket.set_index('index',inplace=True)\n",
    "df_aux['composition_sem_pocket'] = np.nan\n",
    "for c in range(df_aux.shape[0]):\n",
    "    try:\n",
    "        df_aux['composition_sem_pocket'][c] = df_pocket['composition_sem_pocket'][c]\n",
    "    except:\n",
    "        df_aux['composition_sem_pocket'][c] = df_aux['composition'][c]\n",
    "        \n",
    "        \n",
    "# retirando o lining do composition\n",
    "# quem só tiver lining é dado como não fornecido\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "# Ver os que restam sem composition no comp_list\n",
    "index_comp_nao_resolvida = df_aux[df_aux.isna()['composition_list']].index.values\n",
    "\n",
    "# Ver, desses sem comp e sem pocket, quais possuem a palavra lining nele\n",
    "l = []\n",
    "ind = []\n",
    "for index in index_comp_nao_resolvida:\n",
    "    try:\n",
    "        l.append(str(re.search('(lining.+)',df_aux.loc[index,'composition_sem_pocket']).group(1)))\n",
    "        ind.append(index)\n",
    "    except:\n",
    "        pass\n",
    "# criar um df dos que tem lining e não tem pocket\n",
    "df_lining = pd.DataFrame(l,ind)\n",
    "df_lining.reset_index(inplace=True)\n",
    "df_lining.rename(columns={0:'comp'},inplace=True)\n",
    "df_lining = df_lining.join(df_aux.loc[index_comp_nao_resolvida,'composition_sem_pocket'],on='index')\n",
    "\n",
    "# Extraindo as porcentagens\n",
    "df_lining['pct'] = np.nan\n",
    "for c in range(df_lining.shape[0]):\n",
    "    df_lining['pct'][c] = re.findall('(\\d{1,3})%',df_lining.loc[c,'comp'])\n",
    "\n",
    "# Separar as porcentagens de 100 em 100, a primeira é a do lining (pct_lining), as demais não (pct_clothes)\n",
    "pct_lining = []\n",
    "pct_clothes = []\n",
    "for numeros in df_lining['pct']:\n",
    "    soma_anterior = 0\n",
    "    soma_final = 0\n",
    "    count = 0\n",
    "    for num in numeros:\n",
    "            num = int(num)\n",
    "            soma_final = soma_anterior + num\n",
    "            count = count + 1\n",
    "            soma_anterior = soma_final\n",
    "            if soma_final == 100:\n",
    "                pct_clothes.append(numeros[count:].copy())\n",
    "                pct_lining.append(numeros[:count].copy())\n",
    "df_lining['pct_clothes'] = pct_clothes\n",
    "df_lining['pct_lining'] = pct_lining\n",
    "\n",
    "# Tirando só a parte do lining das comp\n",
    "lst_sem_lining = []\n",
    "for index in range(df_lining.shape[0]):\n",
    "        frase = df_lining.loc[index,'composition_sem_pocket']\n",
    "        pattern = '(lining.+{}%)'.format(df_lining.loc[index,'pct_lining'][-1])\n",
    "        lst_sem_lining.append(frase.replace(re.search(pattern,frase).group(1),''))\n",
    "df_lining = pd.concat([df_lining,pd.Series(lst_sem_lining)],axis=1)\n",
    "df_lining.rename(columns={0:'comp_sem_lining'},inplace=True)\n",
    "\n",
    "# se sobrar nada? os vazios n tem composition (pq eles só tinham lining ou só lining e pocket)\n",
    "for index in range(df_lining.shape[0]):\n",
    "    if df_lining.loc[index,'comp_sem_lining'] == ' ':\n",
    "        df_aux.loc[df_lining.loc[index,'index'],'composition_list'] = 'Não fornecido'\n",
    "\n",
    "# se sobrar só as composições, quero colocá-las no meu composition list\n",
    "for c in range(df_lining.shape[0]):\n",
    "    lista_comp = re.findall('(\\d{1,3})%',df_lining.loc[c,'comp_sem_lining'])\n",
    "    for i in range(len(lista_comp)):\n",
    "        lista_comp[i] = float(lista_comp[i])\n",
    "    soma = sum(lista_comp)\n",
    "    if soma == 100 and ':' not in df_lining.loc[c,'comp_sem_lining']:\n",
    "        df_aux['composition_list'][df_lining.loc[c,'index']] = list(filter(None,re.split('%|, | ',df_lining.loc[c,'comp_sem_lining'].replace(', ',''))))\n",
    "\n",
    "# criar nova coluna com os compositions, só que sem o pocket e sem o lining\n",
    "df_lining.set_index('index',inplace=True)\n",
    "df_aux['composition_sem_pocket_e_sem_lining'] = np.nan\n",
    "for c in range(df_aux.shape[0]):\n",
    "    try:\n",
    "        df_aux['composition_sem_pocket_e_sem_lining'][c] = df_lining['comp_sem_lining'][c]\n",
    "    except:\n",
    "        df_aux['composition_sem_pocket_e_sem_lining'][c] = df_aux['composition_sem_pocket'][c] # mantenho o sem pocket, se já n tiver lining\n",
    "        \n",
    "        \n",
    "# retirando o shell do composition\n",
    "\n",
    "# quem só tiver shell a gente bota shell\n",
    "# quem tiver shell + comp a gente bota comp\n",
    "# quem tiver outra categoria a gente bota \"inconclusivo\"\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "# Ver os que restam sem composition no comp_list\n",
    "index_comp_nao_resolvida = df_aux[df_aux.isna()['composition_list']].index.values\n",
    "\n",
    "# Ver, desses sem comp e sem pocket, quais possuem a palavra lining nele\n",
    "l = []\n",
    "ind = []\n",
    "for index in index_comp_nao_resolvida:\n",
    "    try:\n",
    "        l.append(str(re.search('(shell.+)',df_aux.loc[index,'composition_sem_pocket_e_sem_lining']).group(1)))\n",
    "        ind.append(index)\n",
    "    except:\n",
    "        pass\n",
    "# criar um df dos que tem shell e não tem pocket nem lining\n",
    "df_shell = pd.DataFrame(l,ind)\n",
    "df_shell.reset_index(inplace=True)\n",
    "df_shell.rename(columns={0:'comp'},inplace=True)\n",
    "df_shell = df_shell.join(df_aux.loc[index_comp_nao_resolvida,'composition_sem_pocket_e_sem_lining'],on='index')\n",
    "\n",
    "# Extraindo as porcentagens\n",
    "df_shell['pct'] = np.nan\n",
    "for c in range(df_shell.shape[0]):\n",
    "    df_shell['pct'][c] = re.findall('(\\d{1,3})%',df_shell.loc[c,'comp'])\n",
    "\n",
    "# Separar as porcentagens de 100 em 100, a primeira é a do shell (pct_shell), as demais não (pct_clothes)\n",
    "pct_shell = []\n",
    "pct_clothes = []\n",
    "for numeros in df_shell['pct']:\n",
    "    soma_anterior = 0\n",
    "    soma_final = 0\n",
    "    count = 0\n",
    "    for num in numeros:\n",
    "            num = int(num)\n",
    "            soma_final = soma_anterior + num\n",
    "            count = count + 1\n",
    "            soma_anterior = soma_final\n",
    "            if soma_final == 100:\n",
    "                pct_clothes.append(numeros[count:].copy())\n",
    "                pct_shell.append(numeros[:count].copy())\n",
    "df_shell['pct_clothes'] = pct_clothes\n",
    "df_shell['pct_shell'] = pct_shell\n",
    "\n",
    "# Tirando só a parte do shell das comp\n",
    "lst_sem_shell = []\n",
    "for index in range(df_shell.shape[0]):\n",
    "        frase = df_shell.loc[index,'composition_sem_pocket_e_sem_lining']\n",
    "        pattern = '(shell.+{}%)'.format(df_shell.loc[index,'pct_shell'][-1])\n",
    "        lst_sem_shell.append(frase.replace(re.search(pattern,frase).group(1),''))\n",
    "df_shell = pd.concat([df_shell,pd.Series(lst_sem_shell)],axis=1)\n",
    "df_shell.rename(columns={0:'comp_sem_shell'},inplace=True)\n",
    "\n",
    "# se sobrar nada? os vazios so tinham shell, ent vamos usar eles\n",
    "for c in range(df_shell.shape[0]):\n",
    "    if not df_shell.loc[c,'comp_sem_shell'].isalpha():\n",
    "        df_aux['composition_list'][df_shell.loc[c,'index']] = list(filter(None,re.split('%|, | ',df_shell.loc[c,'composition_sem_pocket_e_sem_lining'].replace(', ','').replace('shell: ',''))))\n",
    "    \n",
    "# se sobrar só as composições, quero colocá-las no meu composition list\n",
    "for c in range(df_shell.shape[0]):\n",
    "    lista_comp = re.findall('(\\d{1,3})%',df_shell.loc[c,'comp_sem_shell'])\n",
    "    for i in range(len(lista_comp)):\n",
    "        lista_comp[i] = float(lista_comp[i])\n",
    "    soma = sum(lista_comp)\n",
    "    if soma == 100 and ':' not in df_shell.loc[c,'comp_sem_shell']:\n",
    "        df_aux['composition_list'][df_shell.loc[c,'index']] = list(filter(None,re.split('%|, | ',df_shell.loc[c,'comp_sem_shell'].replace(', ',''))))\n",
    "\n",
    "# criar nova coluna com os compositions, só que sem o pocket sem o lining e sem o shell\n",
    "df_shell.set_index('index',inplace=True)\n",
    "df_aux['composition_sem_pocket_e_sem_lining_e_sem_shell'] = np.nan\n",
    "for c in range(df_aux.shape[0]):\n",
    "    try:\n",
    "        df_aux['composition_sem_pocket_e_sem_lining_e_sem_shell'][c] = df_lining['comp_sem_shell'][c]\n",
    "    except:\n",
    "        df_aux['composition_sem_pocket_e_sem_lining_e_sem_shell'][c] = df_aux['composition_sem_pocket_e_sem_lining'][c] # mantenho o sem pocket e sem lining, se já n tiver shell\n",
    "        \n",
    "        \n",
    "# Ver os que restam sem composition no comp_list\n",
    "index_comp_nao_resolvida = df_aux[df_aux.isna()['composition_list']].index.values\n",
    "for index in index_comp_nao_resolvida:\n",
    "    df_aux.loc[index_comp_nao_resolvida,'composition_list'] = 'Inconclusivo'\n",
    "    \n",
    "dados = pd.concat([dados,df_aux['composition_list']],axis=1)\n",
    "\n",
    "# Transformando as composições em colunas\n",
    "comp_dict = {}\n",
    "comp_list = []\n",
    "\n",
    "for comp in dados['composition_list']:\n",
    "    for c in range(0,len(comp),2):\n",
    "        comp_dict[comp[c]] = comp[c+1]\n",
    "    comp_list.append(comp_dict.copy())\n",
    "\n",
    "df_compositions = pd.DataFrame(comp_list).fillna(0)\n",
    "dados = pd.concat([dados,df_compositions],axis=1)\n",
    "\n",
    "dados.drop(['composition','composition_list'],axis=1,inplace=True) # Drop other composition columns\n",
    "######################################################################################################################################################################################################3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
